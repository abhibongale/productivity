# Standard Errors

- when one is able to truly understand the concept of standard error, many of our most beloved inferential statistics (t tests, ANOVA, regression coefficients, correlations) become easy to understand.
- Inferential statistics is all about using information collected from samples to reach conclusions about the populations the samples came from. In the inferential statistics that we will see, the formulas are all basically the same: How large is the effect that you observe in your sample data compared to the amount of error you would expect to get just due to chance?*(In inferential statistics,** chance means random sampling error, or the error you would expect just due to random sampling.**)* As you will see when we discuss t test, F values, and correlation coefficients, the formulas for the inferential statistics all have this same general formula, with the observed effect in the sample as the numerator of the formulas and the error due to chance as the denominator.


## What Is a Standard Error?

- **The standard error is the measure of how much *random* variation we would expect from samples of equal size drawn from the same population.**

## The Conceptual Description of the Standard Error of the Mean

- Let's describe what is Sampling distribution first. We take out lots of samples from population and those samples have mean and standard deviation. We calculate all samples mean, this mean of all samples form a distribution. This distribution of means (taken from samples) are known as Sampling distribution of the mean.
- The mean of mean(sampling distribution) sample distribution is known as the **expected value of the mean**.
- It is called expected value because the mean of the sampling distribution of the mean is the same as the population mean.
- The Standard deviation of the Sampling distribution of the mean is called standard error.
- So the standard error is simply the standard deviation of the sampling distribution.

---
The final step in understanding the concept of standard error of the mean is to understand what this statistic tells us.

- The standard deviation tells us the average difference, or deviation, between an individual score in the distribution and the mean for the distribution. 
- The standard error of the mean provides essentially the same information, except it refers to the average difference between the expected value (e.g., the population mean) and an individual sample mean.

	- So one way to think about the standard error of the mean is that it tells us how confident we should be that a sample mean represents the actual population mean.
	- Phrased another way, the standard error of the mean provides a measure of how much error we can expect when we say that a sample mean represents the mean of the larger population. That is why it is called a standard error.
	- Knowing how much error we can expect when selecting a sample of a given size from a population is critical in helping us determine whether our sample statistic, such as the sample mean, is meaningfully different from the population parameter, such as the population mean. 
	- This is the foundation of all the inferential statistics.

![Sampling distribution of the mean with the expected value and the standard error shown](../figs/imgse.png)

## How to Calculate the Standard Error of the Mean

- Most of the time, researchers do not draw 1,000 samples of equal size from the population and then figure out the mean and standard deviation of this distribution of sample means.
- In fact, most of the time, researchers collect data from only a single sample, and then use this sample
to make inferences about the population from which the sample was drawn. How can we make inferences about a larger population on the basis of a single sample?
- To do this, researchers must use what they know about their sample to make educated guesses, or estimates, about the population. I demonstrate this concept using the shoe-size example mentioned earlier. Suppose that I have a random sample of 100 women.
- Now, if this sample were truly selected at random (i.e., every adult woman in the country had an equal
chance of being selected), my most logical assumption would be that this sample represents the larger population accurately.
- Therefore, I would have to assume that the mean shoe size of my sample (suppose it is 6) is also the mean shoe size of the larger population.
- Of course, I cannot know if this is true. In fact, as discussed earlier, there is good reason to believe that my sample may not represent my population well. But if the only information I have about adult womenâ€™s shoe sizes comes from my sample of 100 women, my best guess about what the larger population of women looks like must be that they are similar to this sample of 100 women. 
- **Now I am faced with a critical question**: 
1. When I guess that the population of women in the country where I am conducting the study has an average shoe size of 6 (based on my sample average), how much error can I expect to have in this estimation? 
2. In other words, what is the standard error?
3. To answer this question, I must examine two characteristics of my sample. First, how large is
my sample?  The larger my sample, the less error I should have in my estimate about the population. 
This makes sense because the larger my sample, the more my sample should look like my population, and the more accurate my estimates of my population will be. If there are 50 million women in the country where the study is being conducted and I use a sample of 25 million to predict their average shoe size, I would expect this prediction to be more accurate than a prediction based on a sample of 100 women. Therefore, the larger my sample, the smaller my standard error.
4. The second characteristic of my sample that I need to examine is the standard deviation. Remember that the standard deviation is a measure of how much variation there is in the scores in my sample. If the scores in my sample are very diverse (i.e., a lot of variation and therefore a large standard deviation), I can assume that the scores in my population are also quite diverse. 
So, if some women in my sample have a shoe size of 2 and others have a shoe size of 14, I can also assume that there is a pretty large variety of shoe sizes in my population. 
On the other hand, if all of the women in my sample have shoe sizes of either 5, 6, or 7, I can assume that most of the women in the larger population have an equally small variety of shoe sizes. Although these assumptions about the population may not be true (e.g., I may have selected a biased sample from the population), I must rely on them because this is all the information I have. So, the larger the sample standard deviation, the greater the assumed variation of scores in the population, and consequently the larger the standard error of the mean.
- The women in the larger population have an equally small variety of shoe sizes. Although these assumptions about the population may not be true (e.g., I may have selected a biased sample from the population), I must rely on them because this is all the information I have. So, the larger the sample standard deviation, the greater the assumed variation of scores in the population, and consequently the larger the standard error of the mean.
(Note: In those instances where I know the population standard deviation, I can use that in my calculation of the standard error of the mean.)

$$\sigma_{\overline{x}} = \frac{\sigma}{\sqrt{n}}$$ or $$s_{\overline{x}}=\frac{s}{\sqrt{n}}$$

- where $\sigma$ is the standard deviation for the population.
- $s$ is the sample estimate of the standard deviation.
- $n$ size of the sample.

- An examination of the formula for calculating the standard error of the mean reveals the central role of the sample standard deviation (or population standard deviation, if known) and the sample size in determining the standard error. As you can see, the formula is simply the standard deviation of the sample or population divided by the square root of n, the sample size. As with all fractions, as the numerator gets larger, so does the resulting standard error.
- Similarly, as the size of the denominator decreases, the resulting standard error increases. Small samples with large standard deviations produce large standard errors, because these characteristics make it more difficult to have confidence that our sample accurately represents our population. In contrast, a large sample with a small standard deviation will produce a small standard error, because such characteristics make it more likely that our sample accurately represents our population.


## The Central Limit Theorem

- Simply put, the central limit theorem states that as long as you have a reasonably large sample size (e.g., n = 30), the sampling distribution of the mean will be normally distributed, even if the distribution of scores in your sample is not.
- What the central limit theorem proves is that even when you have such a nonnormal distribution in your
population, the sampling distribution of the mean will most likely approximate a nice, normal, bell-shaped distribution as long as you have at least 30 cases in your sample. Even if you have fewer than 30 cases in your sample, the sampling distribution of the me
- For example, I may want to know whether the average IQ test scores of a sample of 50 adults in California is different from the larger population of adults. If my sample has an average IQ test score of 110, and the national average is 100, I can see that my sample average differs from the population average by 10 points.
- Is 10 points a meaningful difference or a trivial one? To answer that question, I must be able to discover the probability of getting a difference of 10 points by random chance alone. (In statistics, the probability of obtaining a statistic by chance is known as the **p value**.) 
- In other words, if I were to select another random sample of 50 adults from California and compute their
average IQ test score, what are the odds that they will have an average that is 10 points higher than the national average of 100? To determine this probability, I must have a normal distribution of sample means, or a normal sampling distribution of the mean.
- The central limit theorem indicates that as long as I have a sample size of at least 30, my sampling distribution of the mean is likely to approximate a normal distribution.


## The Normal Distribution and t Distributions: Comparing z Scores and t Values

- we learned how to determine the probability of randomly selecting an individual case with a particular score on some variable from a population with a given mean on that variable. 
- We did this by converting the raw score into a z score. Now that we know how to compute a standard error, we can use z scores again to determine the probability of randomly selecting a sample with a particular mean on a variable from a population with a given mean on the same variable.
- We can also use the family of t distributions to generate t values to figure out the same types of probabilities. 
- To explain this, I will begin by comparing the normal distribution with the family of t distributions.
-The normal distribution is a theoretical distribution with a bell shape and is based on the idea of population data. We also know that the probabilities associated with z scores are associated with the normal distribution	
- In addition, we know that a standard deviation derived from sample data is only an estimate of the population standard deviation.
- Because the formula for calculating the sample standard deviation has $n â€“ 1$ in the denominator, we also know that the smaller the sample, the less precisely the sample standard deviation estimates the population standard deviation. Finally, we know that the standard error formula (Table 6.2) is based partly on the standard deviation.
- When we put all of this information together, we end up with a little bit of a dilemma. If we can use the standard error to generate z scores and probabilities, and these z scores and probabilities are based on the normal distribution, what do we do in those cases where we are using sample data and we have a small sample? Wonâ€™t our small sample influence our standard error? And wonâ€™t this standard error influence our z scores? Will our z scores and probabilities be accurate if we have a small sample? Fortunately, these concerns have already been addressed by brains larger than my own. 
- **It turns out that the normal distribution has a close family of relatives**: the family of t distributions. These distributions are very much like the normal distribution, except the shape of t distributions is influenced by sample size. With large samples (e.g., > 120), the shape of the t distribution is virtually identical to the normal distribution. As the sample size decreases, however, the shape of the t distribution becomes flatter in the middle and higher at the ends. 
- In other words, as the sample size decreases, there will be fewer cases near the mean and more cases
away from the mean, out in the tails of the distribution. Like the normal distribution, t distribu-
tions are still symmetrical.
- When we put all of this information together, we end up with a little bit of a dilemma. If we can use the standard error to generate z scores and probabilities, and these z scores and probabilities are based on the normal distribution, what do we do in those cases where we are using sample data and we have a small sample? Wonâ€™t our small sample influence our standard error? And wonâ€™t this standard error influence our z scores? Will our z scores and probabilities be accurate if we have a small sample? Fortunately, these concerns have already been addressed by brains larger than my own.
- **It turns out that the normal distribution has a close family of relatives**: the family of t distributions. These distributions are very much like the normal distribution, except the shape of t distributions is influenced by sample size. With large samples (e.g., > 120), the shape of the t distribution is virtually identical to the normal distribution. As the sample size decreases, however, the shape of the t distribution becomes flatter in the middle and higher at the ends.
- In other words, as the sample size decreases, there will be fewer cases near the mean and more cases away from the mean, out in the tails of the distribution. Like the normal distribution, t distributions are still symmetrical.
- 
